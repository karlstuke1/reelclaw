from __future__ import annotations

import json
import os
import re
from dataclasses import dataclass
from pathlib import Path
import typing as t

from .openrouter_client import OpenRouterError, chat_completions


def _strip_code_fences(text: str) -> str:
    s = (text or "").strip()
    s = re.sub(r"^```(?:json)?\\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"\\s*```$", "", s)
    return s.strip()


def _extract_json_object(text: str) -> dict[str, t.Any]:
    cleaned = _strip_code_fences(text)
    start = cleaned.find("{")
    end = cleaned.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise ValueError("No JSON object found in model output")
    snippet = cleaned[start : end + 1]
    try:
        return json.loads(snippet)
    except json.JSONDecodeError:
        # Some models accidentally double-escape JSON.
        if '\\"' in snippet or "\\n" in snippet:
            try:
                unescaped = snippet.encode("utf-8").decode("unicode_escape")
                return json.loads(unescaped)
            except Exception:
                pass
        raise


def _reasoning_param() -> dict[str, t.Any]:
    effort_env = os.getenv("REASONING_EFFORT", "").strip().lower()
    if effort_env == "xhigh":
        effort_env = "high"
    if effort_env in {"none", "minimal", "low", "medium", "high"}:
        return {"effort": effort_env}
    # Default to high to improve story planning; override via REASONING_EFFORT.
    return {"effort": "high"}


def _norm_tag(s: str) -> str:
    return " ".join((s or "").strip().lower().split())


_STOPWORDS = {
    "a",
    "an",
    "and",
    "are",
    "as",
    "at",
    "be",
    "by",
    "for",
    "from",
    "has",
    "have",
    "in",
    "is",
    "it",
    "of",
    "on",
    "or",
    "that",
    "the",
    "this",
    "to",
    "with",
}


def _tokens(text: str) -> set[str]:
    """
    Cheap lexical tokens for fallback planning. Keeps only alnum tokens and strips stopwords.
    This stays meta (no reel-specific rules) and avoids extra model calls.
    """
    s = (text or "").strip().lower()
    if not s:
        return set()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    out: set[str] = set()
    for w in s.split():
        if len(w) < 3:
            continue
        if w in _STOPWORDS:
            continue
        out.add(w)
    return out


def _safe_float(x: t.Any) -> float | None:
    try:
        return float(x)
    except Exception:
        return None


def _fallback_story_plan(
    *,
    segments: list[t.Any],
    group_summaries: list[dict[str, t.Any]],
    niche: str,
    vibe: str,
) -> StoryPlan:
    """
    Deterministic fallback: builds a coherent chapter-ish plan from the tag/description summaries.
    This is used only when the model fails to produce a valid strict-JSON plan.
    """
    n = len(segments)
    # 2 chapters for short edits, 3 for longer ones.
    n_chapters = 2 if n <= 6 else 3
    # Rough splits (deterministic).
    cuts: list[int] = []
    if n_chapters == 2:
        cuts = [max(1, n // 2)]
    else:
        cuts = [max(1, n // 3), max(2, (2 * n) // 3)]

    def _group_score(seg: t.Any, g: dict[str, t.Any]) -> float:
        seg_tags = getattr(seg, "desired_tags", []) or []
        seg_text = " ".join([str(x) for x in seg_tags]) + " " + str(getattr(seg, "reference_visual", "") or "")
        stoks = _tokens(seg_text)

        g_text = " ".join([str(x) for x in (g.get("top_tags") or [])]) + " " + str(g.get("setting") or "") + " " + str(g.get("shot_type") or "") + " " + str(g.get("mood") or "")
        # Include a couple sample descriptions for more signal (already generated by the VLM tagger).
        for d in (g.get("sample_descriptions") or [])[:3]:
            g_text += " " + str(d)
        gtoks = _tokens(g_text)

        overlap = len(stoks.intersection(gtoks)) if stoks and gtoks else 0

        # Lighting proximity (soft): avoid massive day/night mismatches.
        ref_luma = _safe_float(getattr(seg, "ref_luma", None))
        ref_dark = _safe_float(getattr(seg, "ref_dark_frac", None))
        luma_range = g.get("luma_range")
        dark_range = g.get("dark_range")
        light_pen = 0.0
        if ref_luma is not None and isinstance(luma_range, list) and len(luma_range) == 2:
            try:
                mid = (float(luma_range[0]) + float(luma_range[1])) / 2.0
                light_pen += abs(mid - float(ref_luma)) * 2.0
            except Exception:
                pass
        if ref_dark is not None and isinstance(dark_range, list) and len(dark_range) == 2:
            try:
                mid = (float(dark_range[0]) + float(dark_range[1])) / 2.0
                light_pen += abs(mid - float(ref_dark)) * 1.2
            except Exception:
                pass

        sharp = _safe_float(g.get("sharpness_max")) or 0.0
        sharp_bonus = min(0.15, sharp / 4000.0)
        return float(overlap) + float(sharp_bonus) - float(light_pen)

    # Rank groups per segment by score.
    ranked_by_seg: dict[int, list[str]] = {}
    for seg in segments:
        sid = int(getattr(seg, "id", 0) or 0)
        scored: list[tuple[float, str]] = []
        for g in group_summaries:
            gid = str(g.get("sequence_group_id") or "").strip()
            if not gid:
                continue
            scored.append((_group_score(seg, g), gid))
        scored.sort(key=lambda x: x[0], reverse=True)
        ranked_by_seg[sid] = [gid for _s, gid in scored[:12]]

    # Pick chapter primary groups (try to diversify by asset_id).
    group_to_asset = {str(g.get("sequence_group_id") or ""): str(g.get("asset_id") or "") for g in group_summaries}
    primary_by_chapter: list[str] = []
    used_assets: set[str] = set()
    chapter_ranges: list[tuple[int, int]] = []
    start = 0
    for c in cuts + [n]:
        chapter_ranges.append((start, min(n, c)))
        start = c

    for (a, b) in chapter_ranges:
        # Choose a primary group that appears near the top for the chapter start.
        seg0 = segments[a] if a < len(segments) else segments[0]
        sid0 = int(getattr(seg0, "id", 0) or 0)
        choices = ranked_by_seg.get(sid0) or []
        picked = ""
        for gid in choices:
            aid = group_to_asset.get(gid, "")
            if aid and aid in used_assets:
                continue
            picked = gid
            if aid:
                used_assets.add(aid)
            break
        if not picked and choices:
            picked = choices[0]
        primary_by_chapter.append(picked)

    # Build segments with chapter continuity.
    out_segments: list[StoryPlanSegment] = []
    for i, seg in enumerate(segments):
        sid = int(getattr(seg, "id", 0) or 0)
        # Which chapter?
        chap_idx = 0
        for j, (a, b) in enumerate(chapter_ranges):
            if a <= i < b:
                chap_idx = j
                break
        primary = primary_by_chapter[chap_idx] if chap_idx < len(primary_by_chapter) else ""
        ranking = ranked_by_seg.get(sid) or []
        prefs: list[str] = []
        if primary:
            prefs.append(primary)
        # Fill fallbacks with top-ranked alternatives.
        for gid in ranking:
            if gid in prefs:
                continue
            prefs.append(gid)
            if len(prefs) >= 3:
                break
        prefs = [p for p in prefs if p][:3]
        if not prefs and ranking:
            prefs = ranking[:3]

        dtags = [(_norm_tag(str(x)) or "") for x in (getattr(seg, "desired_tags", []) or [])]
        dtags = [t for t in dtags if t][:14]

        trans = None
        if i > 0:
            prev_primary = primary_by_chapter[chap_idx - 1] if chap_idx > 0 and chap_idx - 1 < len(primary_by_chapter) else ""
            if prev_primary and primary and prev_primary != primary and any(i == a for (a, _b) in chapter_ranges[1:]):
                trans = "contrast cut"
            else:
                trans = "continuity cut"

        out_segments.append(
            StoryPlanSegment(
                id=sid,
                story_beat=str(getattr(seg, "beat_goal", "") or "") or "beat",
                preferred_sequence_group_ids=prefs,
                desired_tags=dtags,
                transition_hint=trans,
            )
        )

    concept = f"Fallback story plan for niche='{(niche or '').strip()}' vibe='{(vibe or '').strip()}': hook -> build -> payoff (chaptered)."
    return StoryPlan(plan_id="FALLBACK", concept=concept, segments=out_segments)


def summarize_sequence_groups(
    *,
    shots: list[dict[str, t.Any]],
    max_groups: int = 120,
    max_tags: int = 10,
) -> list[dict[str, t.Any]]:
    """
    Build a compact, model-friendly summary of the library at the sequence_group level.
    This is how the system becomes \"aware\" of the whole library without sending every frame.
    """
    groups: dict[str, list[dict[str, t.Any]]] = {}
    for s in shots:
        gid = str(s.get("sequence_group_id") or "").strip()
        if not gid:
            continue
        groups.setdefault(gid, []).append(s)

    def _score_group(items: list[dict[str, t.Any]]) -> float:
        # Prefer groups with more shots and higher sharpness (very rough signal).
        sharp = 0.0
        for it in items:
            try:
                v = float(it.get("sharpness") or 0.0)
                sharp = max(sharp, v)
            except Exception:
                pass
        return float(len(items)) + (0.001 * sharp)

    ranked = sorted(groups.items(), key=lambda kv: _score_group(kv[1]), reverse=True)
    if max_groups > 0:
        ranked = ranked[: max_groups]

    out: list[dict[str, t.Any]] = []
    for gid, items in ranked:
        asset_id = str(items[0].get("asset_id") or "").strip() if items else ""
        asset_name = ""
        if items:
            try:
                asset_name = Path(str(items[0].get("asset_path") or "")).name
            except Exception:
                asset_name = ""
        # Tag frequency.
        freq: dict[str, int] = {}
        descs: list[str] = []
        shot_types: dict[str, int] = {}
        settings: dict[str, int] = {}
        moods: dict[str, int] = {}
        sample_ids: list[str] = []
        for it in items:
            sid = str(it.get("id") or "").strip()
            if sid and len(sample_ids) < 3:
                sample_ids.append(sid)
            d = str(it.get("description") or "").strip()
            if d:
                descs.append(d)
            for tg in (it.get("tags") or []):
                nt = _norm_tag(str(tg))
                if nt:
                    freq[nt] = freq.get(nt, 0) + 1
            for k, bucket in (("shot_type", shot_types), ("setting", settings), ("mood", moods)):
                v = str(it.get(k) or "").strip().lower()
                if v:
                    bucket[v] = bucket.get(v, 0) + 1

        top_tags = [k for k, _v in sorted(freq.items(), key=lambda kv: kv[1], reverse=True)[: max_tags]]
        top_shot_type = max(shot_types.items(), key=lambda kv: kv[1])[0] if shot_types else ""
        top_setting = max(settings.items(), key=lambda kv: kv[1])[0] if settings else ""
        top_mood = max(moods.items(), key=lambda kv: kv[1])[0] if moods else ""

        # Simple numeric ranges.
        def _safe_floats(key: str) -> list[float]:
            vals: list[float] = []
            for it in items:
                try:
                    x = float(it.get(key))
                except Exception:
                    continue
                vals.append(float(x))
            return vals

        lumas = _safe_floats("luma_mean")
        darks = _safe_floats("dark_frac")
        motions = _safe_floats("motion_score")
        sharps = _safe_floats("sharpness")

        out.append(
            {
                "sequence_group_id": gid,
                "asset_id": asset_id or None,
                "asset_name": asset_name or None,
                "n_shots": len(items),
                "top_tags": top_tags,
                "shot_type": top_shot_type or None,
                "setting": top_setting or None,
                "mood": top_mood or None,
                "luma_range": [min(lumas), max(lumas)] if lumas else None,
                "dark_range": [min(darks), max(darks)] if darks else None,
                "motion_range": [min(motions), max(motions)] if motions else None,
                "sharpness_max": max(sharps) if sharps else None,
                "sample_shot_ids": sample_ids,
                "sample_descriptions": descs[:4],
            }
        )
    return out


@dataclass(frozen=True)
class StoryPlanSegment:
    id: int
    story_beat: str
    preferred_sequence_group_ids: list[str]
    desired_tags: list[str]
    transition_hint: str | None = None


@dataclass(frozen=True)
class StoryPlan:
    plan_id: str
    concept: str
    segments: list[StoryPlanSegment]


def plan_story_plans(
    *,
    api_key: str,
    model: str,
    segments: list[t.Any],
    group_summaries: list[dict[str, t.Any]],
    niche: str = "",
    vibe: str = "",
    music_doc: dict[str, t.Any] | None,
    timeout_s: float = 240.0,
    site_url: str | None = None,
    app_name: str | None = None,
    num_plans: int = 3,
) -> list[StoryPlan]:
    """
    Create a few coherent storyline options. Output is used as constraints for retrieval/optimization.
    This prompt is deliberately meta (works for any footage / any reel).
    """
    if not segments:
        return []
    if not group_summaries:
        return []

    num_plans = int(max(1, min(5, num_plans)))

    # Compact sections summary for music-aware planning.
    sections = []
    if isinstance(music_doc, dict):
        sec = music_doc.get("sections") or []
        if isinstance(sec, list):
            for s in sec[:8]:
                if not isinstance(s, dict):
                    continue
                sections.append(
                    {
                        "name": str(s.get("name") or ""),
                        "start_beat": int(s.get("start_beat") or 0),
                        "end_beat": int(s.get("end_beat") or 0),
                        "energy": float(s.get("energy") or 0.0),
                    }
                )

    seg_rows: list[dict[str, t.Any]] = []
    for s in segments:
        seg_rows.append(
            {
                "id": int(getattr(s, "id", 0) or 0),
                "duration_s": float(getattr(s, "duration_s", 0.0) or 0.0),
                "beat_goal": str(getattr(s, "beat_goal", "") or ""),
                "desired_tags_hint": [str(x) for x in (getattr(s, "desired_tags", []) or [])][:10],
                "reference_visual_hint": str(getattr(s, "reference_visual", "") or "")[:140],
            }
        )

    # Keep group list trimmed. We pass only text, not images, to stay cheap.
    groups = group_summaries[: min(len(group_summaries), 120)]
    group_to_asset: dict[str, str] = {}
    for g in groups:
        gid = str(g.get("sequence_group_id") or "").strip()
        aid = str(g.get("asset_id") or "").strip()
        if gid and aid:
            group_to_asset[gid] = aid

    # Library-level stats help the model plan a story that actually uses what's available.
    def _top_counts(items: list[str], k: int = 8) -> list[dict[str, t.Any]]:
        freq: dict[str, int] = {}
        for it in items:
            s = (it or "").strip().lower()
            if not s:
                continue
            freq[s] = freq.get(s, 0) + 1
        return [{"key": k0, "count": int(v0)} for k0, v0 in sorted(freq.items(), key=lambda kv: kv[1], reverse=True)[:k]]

    settings = [str(g.get("setting") or "") for g in groups if str(g.get("setting") or "").strip()]
    shot_types = [str(g.get("shot_type") or "") for g in groups if str(g.get("shot_type") or "").strip()]
    moods = [str(g.get("mood") or "") for g in groups if str(g.get("mood") or "").strip()]
    all_tags: list[str] = []
    for g in groups:
        for tg in (g.get("top_tags") or [])[:10]:
            all_tags.append(str(tg))

    # Hard-ish constraints for plan validity.
    n_segments = len(seg_rows)
    # Encourage coverage, but allow chapter-level continuity so the result doesn't feel random.
    # (A human editor often stays in one "scene" for a couple beats before switching.)
    min_unique_groups = int(max(3, round(n_segments * 0.45)))
    min_unique_groups = min(min_unique_groups, max(1, len(groups)))
    # Also enforce diversity at the source-video level, otherwise the model can pick many
    # distinct group IDs that all come from the same 1-2 underlying clips.
    # Keep this achievable: chapters require some repeats, so we can't demand near-1:1 asset usage.
    min_unique_assets = int(max(3, round(n_segments * 0.40)))
    min_unique_assets = min(min_unique_assets, max(1, len({str(g.get("asset_id") or "") for g in groups if str(g.get("asset_id") or "")})))
    max_group_reuse = 3

    system_prompt = "\n".join(
        [
            "You are an ELITE short-form video EDITOR and STORY ARCHITECT.",
            "You are given a library of available footage groups (sequence_group_id) and a target niche/vibe.",
            "You must plan a coherent storyline that uses ONLY the provided group IDs.",
            "",
            "Goal:",
            "- Make the edit feel intentional (not random): hook -> escalation -> payoff.",
            "- Keep visual continuity where it helps (lighting/color/setting), and use contrast intentionally for impact.",
            "- Match the pacing to the provided segment timing and (if present) music sections/energy.",
            "- Avoid monotony: across a plan, prefer USING MANY DIFFERENT sequence_group_id values.",
            f"- Use at least {min_unique_groups} UNIQUE first-choice sequence_group_id values across segments (unless the library is smaller).",
            f"- Also use at least {min_unique_assets} UNIQUE first-choice asset_id values across segments (unless the library is smaller).",
            f"- Reuse the same first-choice sequence_group_id at most {max_group_reuse} times total.",
            "- Organize the edit into 2-3 chapters (mini-arcs): establish -> build -> peak.",
            "- For each chapter, pick a PRIMARY sequence_group_id and use it for 2-3 segments in that chapter (use 0-1 cutaways).",
            "- It is OK (often good) to keep 2 consecutive segments in the SAME group for continuity within a chapter.",
            "- Avoid staying in the same group for too long (3+ consecutive segments) unless the library is tiny.",
            "- IMPORTANT: Do NOT make every segment a different first-choice group. At least one group must repeat as the first-choice to create chapter continuity.",
            "",
            "Rules:",
            "- Do NOT reference specific real people, brand names, or video titles.",
            "- Do NOT invent footage that is not in the library; choose from provided sequence_group_id only.",
            "- Keep this meta: your logic must generalize to ANY library and ANY reference reel.",
            "- For each segment, choose 1-3 preferred sequence_group_ids (ranked best->fallback).",
            "- desired_tags should be short, lowercase, generic; 6-14 tags max.",
            "",
            "Return ONLY strict JSON with this schema:",
            "{",
            '  \"plans\": [',
            "    {",
            '      \"plan_id\": \"A\",',
            '      \"concept\": string,',
            '      \"segments\": [',
            "        {",
            '          \"id\": 1,',
            '          \"story_beat\": string,',
            '          \"preferred_sequence_group_ids\": [\"...\"],',
            '          \"desired_tags\": [\"...\"],',
            '          \"transition_hint\": string',
            "        }",
            "      ]",
            "    }",
            "  ]",
            "}",
        ]
    ).strip()

    user_text = json.dumps(
        {
            "niche": " ".join((niche or "").split()),
            "vibe": str(vibe),
            "music_sections": sections or None,
            "library_stats": {
                "n_groups": len(groups),
                "top_settings": _top_counts(settings),
                "top_shot_types": _top_counts(shot_types),
                "top_moods": _top_counts(moods),
                "top_tags": _top_counts(all_tags),
            },
            "segments": seg_rows,
            "sequence_groups": groups,
            "num_plans": num_plans,
        },
        indent=2,
    )

    known_groups = {str(g.get("sequence_group_id") or "") for g in groups if str(g.get("sequence_group_id") or "")}

    def _parse(doc: dict[str, t.Any]) -> list[StoryPlan]:
        plans_raw = doc.get("plans") or []
        if not isinstance(plans_raw, list) or not plans_raw:
            return []
        out: list[StoryPlan] = []
        for item in plans_raw[:num_plans]:
            if not isinstance(item, dict):
                continue
            pid = str(item.get("plan_id") or "").strip() or "A"
            concept = str(item.get("concept") or "").strip()
            segs_raw = item.get("segments") or []
            if not isinstance(segs_raw, list):
                continue
            segs: list[StoryPlanSegment] = []
            for s in segs_raw:
                if not isinstance(s, dict):
                    continue
                sid = int(s.get("id") or 0)
                if sid <= 0:
                    continue
                beat = str(s.get("story_beat") or "").strip()
                gids = [str(x).strip() for x in (s.get("preferred_sequence_group_ids") or []) if str(x).strip()]
                gids = [g for g in gids if g in known_groups]
                if not gids:
                    continue
                dtags = [_norm_tag(str(x)) for x in (s.get("desired_tags") or []) if _norm_tag(str(x))]
                dtags = dtags[:14]
                segs.append(
                    StoryPlanSegment(
                        id=sid,
                        story_beat=beat,
                        preferred_sequence_group_ids=gids[:3],
                        desired_tags=dtags,
                        transition_hint=str(s.get("transition_hint") or "").strip() or None,
                    )
                )
            if segs:
                out.append(StoryPlan(plan_id=pid, concept=concept, segments=sorted(segs, key=lambda x: x.id)))
        return out

    def _is_valid(plan: StoryPlan) -> bool:
        # Require reasonable coverage and diversity on first-choice group IDs.
        if not plan.segments:
            return False
        covered = {int(s.id) for s in plan.segments if int(s.id) > 0}
        if len(covered) < max(1, int(round(n_segments * 0.85))):
            return False
        first_choices = [s.preferred_sequence_group_ids[0] for s in plan.segments if s.preferred_sequence_group_ids]
        uniq = set(first_choices)
        if len(uniq) < min_unique_groups:
            return False
        # Require at least one repeated first-choice group to encourage chapter continuity.
        if len(first_choices) >= 4 and len(uniq) == len(first_choices) and len(groups) >= 6:
            return False
        # Cap reuse.
        counts: dict[str, int] = {}
        for g in first_choices:
            counts[g] = counts.get(g, 0) + 1
            if counts[g] > max_group_reuse:
                return False
        # Require asset diversity on first-choice picks.
        if min_unique_assets >= 2:
            assets = []
            for g in first_choices:
                a = group_to_asset.get(str(g), "")
                if a:
                    assets.append(a)
            uniq_assets = set(assets)
            if assets and len(uniq_assets) < min_unique_assets:
                return False
            # Prevent collapsing onto 1-2 assets even if group IDs differ.
            asset_counts: dict[str, int] = {}
            for a in assets:
                asset_counts[a] = asset_counts.get(a, 0) + 1
                if asset_counts[a] > max(3, int(round(n_segments * 0.55))):
                    return False
        # Allow short continuity runs, but prevent long monotonous streaks.
        streak = 1
        for a, b in zip(first_choices, first_choices[1:], strict=False):
            if a == b:
                streak += 1
                if streak >= 4:
                    return False
            else:
                streak = 1
        return True

    # Try once with a slightly creative temperature, then retry more deterministic. If the plan
    # violates our diversity/coverage constraints, ask for a reprint with explicit fixes.
    temps = [0.25, 0.10]
    last_text = ""
    for temp in temps:
        result = chat_completions(
            api_key=api_key,
            model=model,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
            temperature=float(temp),
            max_tokens=2400,
            timeout_s=timeout_s,
            site_url=site_url,
            app_name=app_name,
            reasoning=_reasoning_param(),
            retries=3,
            retry_delay_s=2.0,
        )
        last_text = result.content or ""
        try:
            doc = _extract_json_object(last_text)
        except Exception:
            continue
        parsed = _parse(doc)
        parsed = [p for p in parsed if _is_valid(p)]
        if parsed:
            return parsed

    # One more attempt with explicit correction guidance if we got JSON but it was invalid.
    try:
        doc = _extract_json_object(last_text)
        parsed0 = _parse(doc)
    except Exception:
        parsed0 = []
    if parsed0 and any(not _is_valid(p) for p in parsed0):
        fix_msg = (
            f"Your last plans violated constraints. Reprint {num_plans} plans with: "
            f">= {min_unique_groups} unique first-choice group IDs, >= {min_unique_assets} unique first-choice asset_id, "
            f"AND at least one repeated first-choice group (chapter continuity), <= {max_group_reuse} reuse, no 4+ consecutive repeats, and cover all segments."
        )
        result = chat_completions(
            api_key=api_key,
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text},
                {"role": "user", "content": fix_msg},
            ],
            temperature=0.1,
            max_tokens=2400,
            timeout_s=timeout_s,
            site_url=site_url,
            app_name=app_name,
            reasoning=_reasoning_param(),
            retries=3,
            retry_delay_s=2.0,
        )
        last_text = result.content or ""
        try:
            doc = _extract_json_object(last_text)
            parsed = [p for p in _parse(doc) if _is_valid(p)]
            if parsed:
                return parsed
        except Exception:
            pass

    # If we could parse plans but they missed some constraints, return the best-effort parse
    # instead of failing hard (callers treat story planning as an optional enhancer).
    try:
        doc = _extract_json_object(last_text)
        parsed_loose = _parse(doc)
        if parsed_loose:
            return parsed_loose[:num_plans]
    except Exception:
        pass

    # Deterministic fallback: still meta and library-aware (via tags/descriptions).
    return [_fallback_story_plan(segments=segments, group_summaries=groups, niche=niche, vibe=vibe)]


def save_story_plans(plans: list[StoryPlan], path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    doc = {
        "version": 1,
        "plans": [
            {
                "plan_id": p.plan_id,
                "concept": p.concept,
                "segments": [
                    {
                        "id": s.id,
                        "story_beat": s.story_beat,
                        "preferred_sequence_group_ids": s.preferred_sequence_group_ids,
                        "desired_tags": s.desired_tags,
                        "transition_hint": s.transition_hint,
                    }
                    for s in p.segments
                ],
            }
            for p in plans
        ],
    }
    path.write_text(json.dumps(doc, indent=2), encoding="utf-8")


def load_story_plans(path: Path) -> list[StoryPlan]:
    if not path.exists():
        return []
    doc = json.loads(path.read_text(encoding="utf-8"))
    plans_raw = doc.get("plans") or []
    if not isinstance(plans_raw, list):
        return []
    out: list[StoryPlan] = []
    for p in plans_raw:
        if not isinstance(p, dict):
            continue
        pid = str(p.get("plan_id") or "").strip() or "A"
        concept = str(p.get("concept") or "").strip()
        segs_raw = p.get("segments") or []
        if not isinstance(segs_raw, list):
            continue
        segs: list[StoryPlanSegment] = []
        for s in segs_raw:
            if not isinstance(s, dict):
                continue
            sid = int(s.get("id") or 0)
            if sid <= 0:
                continue
            beat = str(s.get("story_beat") or "").strip()
            gids = [str(x).strip() for x in (s.get("preferred_sequence_group_ids") or []) if str(x).strip()]
            dtags = [_norm_tag(str(x)) for x in (s.get("desired_tags") or []) if _norm_tag(str(x))]
            segs.append(
                StoryPlanSegment(
                    id=sid,
                    story_beat=beat,
                    preferred_sequence_group_ids=gids[:3],
                    desired_tags=dtags[:14],
                    transition_hint=str(s.get("transition_hint") or "").strip() or None,
                )
            )
        if segs:
            out.append(StoryPlan(plan_id=pid, concept=concept, segments=sorted(segs, key=lambda x: x.id)))
    return out
